{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checklist for submission\n",
    "\n",
    "It is extremely important to make sure that:\n",
    "\n",
    "1. Everything runs as expected (no bugs when running cells);\n",
    "2. The output from each cell corresponds to its code (don't change any cell's contents without rerunning it afterwards);\n",
    "3. All outputs are present (don't delete any of the outputs);\n",
    "4. Fill in all the places that say `YOUR CODE HERE`, or \"**Your answer:** (fill in here)\".\n",
    "5. You **ONLY** change the parts of the code we asked you to, nowhere else (change only the coding parts saying `# YOUR CODE HERE`, nothing else);\n",
    "6. Don't add any new cells to this notebook;\n",
    "7. Fill in your group number and the full names of the members in the cell below;\n",
    "8. Make sure that you are not running an old version of IPython (we provide you with a cell that checks this, make sure you can run it without errors).\n",
    "\n",
    "Failing to meet any of these requirements might lead to either a subtraction of POEs (at best) or a request for resubmission (at worst).\n",
    "\n",
    "We advise you the following steps before submission for ensuring that requirements 1, 2, and 3 are always met: **Restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). This might require a bit of time, so plan ahead for this (and possibly use Google Cloud's GPU in HA1 and HA2 for this step). Finally press the \"Save and Checkout\" button before handing in, to make sure that all your changes are saved to this .ipynb file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Group number and member names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP = \"62\"\n",
    "NAME1 = \"Dimitrios Karypidis\"\n",
    "NAME2 = \"Kevin Jaquier\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you can run the following cell without errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "assert IPython.version_info[0] >= 3, \"Your version of IPython is too old, please update it.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f0dd7cbad727dec0308b03071cff6d79",
     "grade": false,
     "grade_id": "cell-8092c3fd452a3245",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# HA1 - Cats and dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "87ccf483a45725dd262468c44d2acbae",
     "grade": false,
     "grade_id": "cell-0235e816fc98b0f6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<img src=\"http://lghttp.32478.nexcesscdn.net/80E972/organiclifestylemagazine/wp-content/uploads/2015/10/Cats-and-Dogs.jpg\" alt=\"Cats and dogs\" style=\"width: 5000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e42d5a9a7b415bb217a6b890b6f07c84",
     "grade": false,
     "grade_id": "cell-c4bb694612153106",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "For this home assignment, we'll use the Kaggle dataset for the [Dogs vs. Cats competition](https://www.kaggle.com/c/dogs-vs-cats). It is comprised of 25k colored images of dogs and cats. Our goal with this dataset will be to create a classifier that can tell us if the input image is of a cat or a dog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a way of helping you speed up the training process, each group gets 6 hours of access to an instance in Google Cloud with a K80 GPU. Take a look at the [Instructions folder](https://github.com/JulianoLagana/deep-machine-learning/tree/master/Instructions) to understand how to connect to this instance and use our tools there. You're free to use this resource as you see fit, but if you run out of hours you'll need a late day to obtain more (and you can only do this once).\n",
    "\n",
    "In order to make the most out of your GPU hours, first try solving the initial part of this notebook (tasks 0-4) in your own computer (these tasks can be solved only on the CPU), and leave most of the available hours for solving tasks 5-6, and refining your best model further (and, if you have the spare hours, experiment a bit!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ba437754e558ff25301e1526ca957f4b",
     "grade": false,
     "grade_id": "cell-f7371c24b57c153e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Requirements:\n",
    "- Whenever we ask you to plot anything, be sure to add a title and label the axes. If you're plotting more than one curve in the same plot, also add a legend.\n",
    "- When we ask you to train an architecture, train it for a reasonable number of epochs. \"Reasonable\" here means you should be fairly confident that training for a higher number of epochs wouldn't impact your conclusions regarding the model's performance.\n",
    "\n",
    "Tips:\n",
    "- If you get errors saying you've exhausted the GPU resources, well, then you exhausted the GPU resources ;). However, sometimes that's because TensorFlow didn't release a part of the GPU's memory. If you think your CNN should fit in your memory during training, try restarting the kernel and directly training only that architecture.\n",
    "- Every group has enough credits on google cloud to complete this assignment. However, this statement assumes you'll use your resources judiciously (e.g. always try the code first in your machine and make sure everything works properly before starting your instances) and **won't forget to stop your instance after using it,**  otherwise you might run out of credits.\n",
    "- Before starting, take a look at the images we'll be using. This is a hard task, don't get discouraged if your first models perform poorly (several participants in the original competition didn't achieve an accuracy higher than 60%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9f50e27a30d83bcebeb52a8ae43228e2",
     "grade": false,
     "grade_id": "cell-3ee6d24346a80d85",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## 0. Imports\n",
    "\n",
    "In the following cell, add all the imports you'll use in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0075c816ac7a24f2287d6fa9b8a81565",
     "grade": true,
     "grade_id": "cell-464a08ede00083a4",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# Packages for defining the architecture of our model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Dense, Flatten, BatchNormalization, Dropout, Input\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "# One-hot encoding\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# Callbacks for training\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "\n",
    "from keras.applications import vgg16\n",
    "\n",
    "# Ploting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Ndarray computations\n",
    "import numpy as np\n",
    "\n",
    "# Confusion matrix for assessment step\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Seaborn plotting tools\n",
    "import seaborn as sns\n",
    "\n",
    "# Python utilities\n",
    "from itertools import islice\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 6,6\n",
    "sns.set(rc={'figure.figsize':(16,6)})\n",
    "sns.set(font_scale=1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "49bf801d5ced99ccf6f0c5cd12100230",
     "grade": false,
     "grade_id": "cell-4821dc273028d702",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## 1. Loading the data and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d1d586c0063030cd1a3b04fe87e189f0",
     "grade": false,
     "grade_id": "cell-2ea049dea4713494",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The first step is to head to the [Kaggle website for the cats and dogs competition](https://www.kaggle.com/c/dogs-vs-cats) and download the data from there. You should download both the test and train folders together in one zip file (by clicking the download all button). The split ratio between training and validation has not been made, you'll need to do it yourself. The `test.zip` file contains unlabeled data, so that participants in the contest are not able to train on this set.\n",
    "\n",
    "For this assignment you should use [data generators](https://keras.io/preprocessing/image/) to load the images to your CPU/GPU memory. Because of this, your folder structure for the data should conform to the folder structure expected by the data generators (i.e. the samples should be separated into one folder for each class). Furthermore, we ask you to first start with a smaller subset of the data (1/5 of the number of samples), in order to test different models faster.\n",
    "\n",
    "This means that you should create a folder structure that resembles the following (obviously, the folder names are up to you):\n",
    "\n",
    "\n",
    "         small_train             small_val                train                   val\n",
    "              |                      |                      |                      |\n",
    "              |                      |                      |                      |\n",
    "        -------------          -------------          -------------          -------------\n",
    "        |           |          |           |          |           |          |           |\n",
    "        |           |          |           |          |           |          |           |\n",
    "      Cats        Dogs       Cats        Dogs       Cats        Dogs       Cats        Dogs\n",
    "\n",
    "The `small_train` and `small_val` folders have the training and validation samples for your smaller subset of the data, while the `train` and `val` folders contain all the samples you extracted from Kaggle's `train.zip`. We provide you a notebook that shows how to achieve this (\"Create project structure.ipynb\"), starting from the original `all.zip` file that you download from Kaggle. If you do use that notebook, we encourage you to understand how each step is being done, so you can generalize this knowledge to new datasets you'll encounter.\n",
    "\n",
    "We advise you to use 30% of the data as validation data in the smaller dataset. However, for the larger dataset, you should decide how to split between training and validation. Please specify your splits in the following cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "21f8c413dbd2a629e479abc65e02c1a1",
     "grade": false,
     "grade_id": "cell-89ba19509b952af2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "For the larger subset, what was the training/validation split that you decided to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b5740099dceee0e312b1711006e99c1f",
     "grade": false,
     "grade_id": "cell-b0efa9a80e35cb50",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**% Samples in the training set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0345d9abbe8e41a3d79a43e58cf61bbd",
     "grade": true,
     "grade_id": "cell-7f3b0dfbd90a14c1",
     "locked": false,
     "points": 0.25,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "n_train = 11875 + 11875"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2ddce1febefd28de63c23277971779d3",
     "grade": false,
     "grade_id": "cell-c23e59a345aa4071",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**% Samples in the validation set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b8cd8215973c0496aaed775aa00d9052",
     "grade": true,
     "grade_id": "cell-515a15da68038afe",
     "locked": false,
     "points": 0.25,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "n_val = 625 + 625"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f907f0a06aa01c1087ab6e18710c2fbe",
     "grade": false,
     "grade_id": "cell-876ca7df88c9311f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Fill in the dataset paths (to be used later by your data generators):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "99224aa0ced417acf27d271313ab4ca2",
     "grade": true,
     "grade_id": "cell-1b1314f2ab1b1d6b",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "train_data_path = './train'\n",
    "val_data_path = './val'\n",
    "train_data_path_small = './small_train'\n",
    "val_data_path_small = './small_val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b5cab872fd6c9d35842bc8b3708e1b7c",
     "grade": false,
     "grade_id": "cell-1d6ea64bca94a4ef",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "Once you have the expected folder structure, create two data generators for automatically generating batches from the images in your smaller subset of data. Don't use any [data augmentation](https://cartesianfaith.com/2016/10/06/what-you-need-to-know-about-data-augmentation-for-machine-learning/), but feel free to preprocess the data as you see fit. After instantiating them, run the `flow_from_directory` method with the desired arguments.\n",
    "\n",
    "Hints:\n",
    "- The specified `batch_size` should be chosen so that your don't run out of memory.\n",
    "- When feeding the images to your CNN, you'll probably want all of them to have the same spatial size, even though the .jpeg files differ in this. If so, take a look at the argument `target_size` for the `flow_from_directory` method of data generators.\n",
    "- Resizing the images to a smaller size while loading them can be beneficial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ccd3d3780bee365018f2a96b8022d56b",
     "grade": true,
     "grade_id": "cell-ed8f5ab8d5cc0d6c",
     "locked": false,
     "points": 1.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3500 images belonging to 2 classes.\n",
      "Found 3500 images belonging to 2 classes.\n",
      "Found 1500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "def load_subset(data_path, n_samples, target_size, generator_options={}, seed=None):\n",
    "    subset_datagen = ImageDataGenerator(\n",
    "        **generator_options,\n",
    "    )\n",
    "\n",
    "    subset_generator = subset_datagen.flow_from_directory(\n",
    "            data_path,\n",
    "            target_size=target_size,\n",
    "            batch_size=1,\n",
    "            seed=seed)\n",
    "\n",
    "    def format_sample(sample):\n",
    "        X, y = sample\n",
    "        X = np.squeeze(X, axis=0)\n",
    "        y = np.squeeze(y, axis=0)\n",
    "        return X, y\n",
    "\n",
    "    subset = list(map(format_sample, islice(subset_generator, n_samples)))\n",
    "    X_subset = np.array([x for x,_ in subset])\n",
    "    y_subset = np.array([y for _,y in subset])\n",
    "    \n",
    "    return X_subset, y_subset\n",
    "\n",
    "img_size = (100, 100)\n",
    "img_w, img_h = img_size\n",
    "rescale_factor = 1./255\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=rescale_factor,\n",
    "    featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    ")\n",
    "\n",
    "X_subset, y_subset = load_subset(\n",
    "    data_path=train_data_path_small,\n",
    "    n_samples=1000,\n",
    "    target_size=img_size,\n",
    "    generator_options={'rescale': rescale_factor},\n",
    "    seed=142,\n",
    ")\n",
    "\n",
    "datagen.fit(X_subset, seed=142)\n",
    "\n",
    "def get_data_generator(data_path):\n",
    "    return datagen.flow_from_directory(\n",
    "            data_path,\n",
    "            target_size=img_size,\n",
    "            batch_size=batch_size,\n",
    "            class_mode=\"binary\",\n",
    "            seed=42)\n",
    "\n",
    "train_generator = get_data_generator(train_data_path_small)\n",
    "val_generator = get_data_generator(val_data_path_small)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9e39d5fb0e38a44e07a4519f4db98583",
     "grade": false,
     "grade_id": "cell-c0bfc1ac7fadfcc7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## 2. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "41dd6aa5a0bc2a35b880c6e72db8e130",
     "grade": false,
     "grade_id": "cell-2c2425121bcacf34",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Create your first CNN architecture for this task. Start with something as simple as possible, that you're almost sure can get an accuracy better than 50% (we'll improve upon it later).\n",
    "\n",
    "Tip:\n",
    "- If Tensorflow is your backend, your `input_shape` is always `(img_width, img_height, 3)` (i.e. channels **last**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d2c30c88e647d05bd81604c1339a68e7",
     "grade": true,
     "grade_id": "cell-4c9de348cd8bc4ff",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "def initial_model():   \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(img_w, img_h, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5210173277189c7bc5d5c18621a1ef8c",
     "grade": false,
     "grade_id": "cell-cb6fc78116ad6b75",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Train your model using the `fit_generator` method and the two data generators you created earlier. Train for a reasonable amount of epochs, so as to get a good sense of how well this architecture performs.\n",
    "\n",
    "Tips:\n",
    "- Usually the bottleneck is when loading the images from the disk. To speed up training, make sure to take a look at the arguments `workers` and `use_multiprocessing` of `fit_generator`.\n",
    "- You don't have to set the argument `steps_per_epoch` to the number of batches in an epoch. Instead, you can choose a lower number to obtain more frequent prints about the current loss and accuracy of your model (but then have in mind that you're not actually training for the number of epochs you specify in `epochs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "865326597e6d487caaaa64ba30cf1abe",
     "grade": true,
     "grade_id": "cell-bb1fcd878f3bea9a",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 10/218 [>.............................] - ETA: 2:27 - loss: 4.8592 - acc: 0.6083"
     ]
    }
   ],
   "source": [
    "model = initial_model()\n",
    "\n",
    "history = model.fit_generator(train_generator, epochs=20, verbose=1,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps= 1500// batch_size,\n",
    "                              steps_per_epoch = 3500// batch_size,\n",
    "                              workers=8, use_multiprocessing=True, \n",
    "                              shuffle=True\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2f494d53c5c891008921b85679b9aaa7",
     "grade": false,
     "grade_id": "cell-4d42c86687697a67",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Create one figure with two axes. In one of them, plot the loss in the training and the validation datasets. In the other one, plot the accuracy in the training and validation datasets.\n",
    "\n",
    "Hint:\n",
    "- The `fit_generator` method returns a `history` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e71729e832321272983178b41b90f874",
     "grade": true,
     "grade_id": "cell-fa81712e1e27432a",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b856bb9d08be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_metric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics_items\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training performance (initial)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def plot_history(ax, history, ylabel, metrics):\n",
    "    metrics_items = metrics.items()\n",
    "    for _label, metric in metrics_items:\n",
    "        ax.plot(history.history[metric], '-o')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.legend([label for label, _metric in metrics_items])\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "f.suptitle('Training performance (initial)')\n",
    "plot_history(ax1, history, 'Loss', {'Training': 'loss', 'Validation': 'val_loss'})\n",
    "plot_history(ax2, history, 'Accuracy', {'Training': 'acc', 'Validation': 'val_acc'})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5797f9d2d079b67832722cebe8cff0ef",
     "grade": false,
     "grade_id": "cell-f2fc166890962bcf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Based on these, what would you suggest for improving your model? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cf197ef63bfa3aee62055bd8ed8f7a1c",
     "grade": true,
     "grade_id": "cell-506e21ce469b67f5",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0be49b9a95620540a192e413f70f71c5",
     "grade": false,
     "grade_id": "cell-db018000a5382694",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## 3. Improving your initial model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "52b66a6d63b9dd6f55f0dfd477b84597",
     "grade": false,
     "grade_id": "cell-fa0e4d84ef7af322",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Improve your initial model according to you answer above. Write the new definition in the cell below and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a0b92d3cd986908779f53ff2b6fac22f",
     "grade": true,
     "grade_id": "cell-a4a3c7da2ad8161b",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def improved_model():   \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(img_w,img_h, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_generator = get_data_generator(train_data_path_small)\n",
    "val_generator = get_data_generator(val_data_path_small)\n",
    "model_improved = improved_model()\n",
    "\n",
    "history_improved = model_improved.fit_generator(train_generator, \n",
    "                                                epochs=10, verbose=1, \n",
    "                                                validation_data=val_generator,\n",
    "                                                validation_steps= 1500// batch_size,\n",
    "                                                steps_per_epoch = 3500// batch_size,\n",
    "                                                workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a93627bb2c08c83a9d4cb6596ab27de7",
     "grade": false,
     "grade_id": "cell-bcff77954e648d56",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "How does the model perform, compared to the initial model? Create one plot with the training accuracy and another with the validation accuracy of the two scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b18ab0f30b9a4e8e9746f324313fa1b2",
     "grade": true,
     "grade_id": "cell-e4cf90a9c3ae1959",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "f.suptitle('Training performance (improved)')\n",
    "plot_history(ax1, history_improved, 'Loss', {'Training': 'loss', 'Validation': 'val_loss'})\n",
    "plot_history(ax2, history_improved, 'Accuracy', {'Training': 'acc', 'Validation': 'val_acc'})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5e771b76bc948242070767d51688eeee",
     "grade": false,
     "grade_id": "cell-14b1810989c351b4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Did your results improve? Explain why, or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "30a59a5574ab183d17b3f92f8057aba4",
     "grade": true,
     "grade_id": "cell-1d27850a74139e5a",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** (By intoducing a deeper model, we increased the non-linearities and the receptive field of the network. Moreover, by introducing a Drop-out operation we decreased the influence of the most persistent patterns, thus decreased overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "67dce4bccc56629263ef4839e570f12a",
     "grade": false,
     "grade_id": "cell-ee79a83a62b70a8f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## 4. Obtaining the *best* model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6d029dd4346c9e32b725e6158d77475c",
     "grade": false,
     "grade_id": "cell-5314d286e79e0377",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Continue to improve your model architecture by comparing the value of the metrics you're interested in both the training and validation set. Try different ideas, and consider comparing them using tensorboard. When you're happy with one architecture, copy it in the cell below and train it here. Save the optimization history (i.e. the `history` object returned by the `fit_generator`). You'll use this later to compare your best model with the one using transfer learning.\n",
    "\n",
    "**Note**: When trying different ideas, you'll end up with several different models. However, when submitting your solutions to ping-pong, the cell below must contain only the definition and training of *one* model. Remove all code related to the models that were not chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "45e0af4b6ac1d453b519ba7c65ccb56d",
     "grade": true,
     "grade_id": "cell-6edb7d7e343ab14b",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def best_model():   \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (2, 2), input_shape=(img_w,img_h, 3)),)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64,\n",
    "                    kernel_regularizer=regularizers.l2(0.01),\n",
    "                    activity_regularizer=regularizers.l1(0.01), \n",
    "                    bias_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_generator = get_data_generator(train_data_path_small)\n",
    "val_generator = get_data_generator(val_data_path_small)\n",
    "\n",
    "model_best = best_model()\n",
    "\n",
    "callbacks_best = [\n",
    "    TensorBoard(log_dir='./logs/best'),\n",
    "    EarlyStopping(monitor='val_loss', \n",
    "                  min_delta=0.2,\n",
    "                  patience=5,\n",
    "                  verbose=0, \n",
    "                  mode='auto',\n",
    "                  baseline=0.8,\n",
    "                  restore_best_weights=False),\n",
    "]\n",
    "\n",
    "history_best = model_best.fit_generator(train_generator, epochs=40, verbose=1,\n",
    "                                        callbacks=callbacks_best, \n",
    "                                        validation_data=val_generator,\n",
    "                                        validation_steps= 1500// batch_size,\n",
    "                                        steps_per_epoch = 3500// batch_size,\n",
    "                                        workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3ed8d707a3e3e3e2dc6e09630da26d02",
     "grade": false,
     "grade_id": "cell-d033937b5a8b9875",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Create one figure with two axes. In one of them, plot the loss in the training and the validation datasets. In the other one, plot the accuracy in the training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "88f944698dc9dc353e1933fe16b6de87",
     "grade": true,
     "grade_id": "cell-3df999674672de47",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "f.suptitle('Training performance (best)')\n",
    "plot_history(ax1, history_best, 'Loss', {'Training': 'loss', 'Validation': 'val_loss'})\n",
    "plot_history(ax2, history_best, 'Accuracy', {'Training': 'acc', 'Validation': 'val_acc'})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "69f51481b462b089daee7f896bad2cc3",
     "grade": false,
     "grade_id": "cell-c67bcc4fbec1808e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Save your model](https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model) to disk as a HDF5 file (the architecture, weights and optimizer state). This is simply so you can use it again easily in the later parts of the notebook, without having to keep it in memory or re-training it. The actual `.h5` files you create are not relevant to your ping-pong submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f560cd87a745d9931d137a0224adb847",
     "grade": false,
     "grade_id": "cell-25f9cc8d17491d0d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## 5. Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2f9adb5c8ce6970840bc5d256e74ca69",
     "grade": false,
     "grade_id": "cell-cf9b347fc3ee9255",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now, instead of trying to come up with a good architecture for this task, we'll use the VGG16 architecture, but with the top layers removed (the fully connected + classification layers). We'll substitute them with a single fully connected layer, and a classification layer that makes sense for our problem.\n",
    "\n",
    "However, this model has a very high capacity, and will probably suffer a lot from overfitting if we try to train it from scratch, using only our small subset of data. Instead, we'll start the optimization with the weights obtained after training VGG16 on the ImageNet dataset.\n",
    "\n",
    "Start by loading the VGG16 model without the top layers, from the `applications` submodule from Keras. Make sure to also load the weights obtained from the ImageNet pretraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "984428d972274a469334141d07c8666a",
     "grade": true,
     "grade_id": "cell-01ebc4c9c306b985",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "vgg = vgg16.VGG16(include_top=False, \n",
    "                  weights='imagenet', \n",
    "                  input_shape=(img_w, img_h, 3),\n",
    "                  pooling=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ee2e7869aeb45bf734d52c7559ab6cb6",
     "grade": false,
     "grade_id": "cell-faed8047ef25a60d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Create a new model with the layers you want to add on top of VGG. The kernels and bias in these layers should be initialized randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a22c7aa185d3eca27d8722755b0a41a1",
     "grade": true,
     "grade_id": "cell-56cb37360051a638",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def cats_and_dogs_layer():   \n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, input_shape=(img_w,img_h, 3), kernel_initializer='random_uniform', bias_initializer='random_uniform'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ff49bf63789cfb3023f59b7ff1de074b",
     "grade": false,
     "grade_id": "cell-d746f9eb61e3ea44",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now add the new model on top of VGG.\n",
    "\n",
    "Tip:\n",
    "- The VGG model you loaded from the `applications` submodule is from the [`Model`](https://keras.io/models/model/) class, not the `Sequential` class, so it doesn't have some methods you're used to (like `add`, for instance). It might be helpful to read [this introduction to the Model class](https://keras.io/getting-started/functional-api-guide/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "642f3cbea497868385adff16643091c4",
     "grade": true,
     "grade_id": "cell-76e4aad7fbcf5d05",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(img_w, img_h, 3))\n",
    "feature_extractor = vgg(inputs)\n",
    "classifier = cats_and_dogs_layer()(feature_extractor)\n",
    "vgg_based_model = Model(inputs=inputs, outputs=classifier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e80006261cee156aafe6aac9408f2678",
     "grade": false,
     "grade_id": "cell-f76d1a7f6280af0d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 5.1 Using VGG features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2b12c99269787356513640faa3528233",
     "grade": false,
     "grade_id": "cell-270f8ec140ddfba3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now we're almost ready to train the new model. However, since the top layers of this architecture are being initialized randomly, it's sometimes possible for them to generate large gradients that can wreck the pretraining of the bottom layers. To avoid this, freeze all the VGG layers in your architecture (i.e. signal to the optimizer that these should not be changed during optimization) by setting the `trainable` attribute of them to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "072f414eabdbed6bd1f0baa8e855e48f",
     "grade": true,
     "grade_id": "cell-bfb58ea46c31df0a",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_5 freezed\n",
      "1 vgg16 freezed\n",
      "2 sequential_3 trainable\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(vgg_based_model.layers):\n",
    "   print(i, layer.name, \"trainable\" if layer.trainable else \"freezed\")\n",
    "\n",
    "vgg_based_model.layers[1].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "669e85a9b10286b41f6b40837f009d45",
     "grade": false,
     "grade_id": "cell-b508ede3d760a86b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Create the callbacks (if any) you would like to use, compile the model and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9c8cccd2e638d17af85d50f45cb05ee3",
     "grade": true,
     "grade_id": "cell-5a025e60545ca151",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "vgg_based_model.compile(loss='binary_crossentropy',\n",
    "                        optimizer='adam',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "batch_size = 8\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "train_generator = get_data_generator(train_data_path_small)\n",
    "val_generator = get_data_generator(val_data_path_small)\n",
    "\n",
    "callbacks_vgg = [\n",
    "    TensorBoard(log_dir='./logs/vgg_based'),\n",
    "    EarlyStopping(monitor='val_loss', \n",
    "                  min_delta=0.2,\n",
    "                  patience=5,\n",
    "                  verbose=0, \n",
    "                  mode='auto',\n",
    "                  baseline=0.8,\n",
    "                  restore_best_weights=False),\n",
    "]\n",
    "\n",
    "history_vgg = vgg_based_model.fit_generator(train_generator, epochs=40, verbose=1, \n",
    "                                            callbacks=callbacks_vgg, \n",
    "                                            validation_data=val_generator,\n",
    "                                            validation_steps= 1500// batch_size,\n",
    "                                            steps_per_epoch = 3500// batch_size,\n",
    "                                            workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f4045831d222640d7baf44a285c3de97",
     "grade": false,
     "grade_id": "cell-ad79e1aa5c4a6185",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Create one figure with two axes. In one of them, plot the loss in the training and the validation datasets. In the other one, plot the accuracy in the training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "99986b7bbdfb6b78c25112751969d11f",
     "grade": true,
     "grade_id": "cell-f17c882b2a09dee7",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history_vgg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-dc6690e23468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training performance (VGG + custom layer)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_vgg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'Training'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Validation'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_vgg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'Training'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Validation'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history_vgg' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "f.suptitle('Training performance (VGG + custom layer)')\n",
    "plot_history(ax1, history_vgg, 'Loss', {'Training': 'loss', 'Validation': 'val_loss'})\n",
    "plot_history(ax2, history_vgg, 'Accuracy', {'Training': 'acc', 'Validation': 'val_acc'})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7e3c0eb41e650ec3e30733ab5ea488d1",
     "grade": false,
     "grade_id": "cell-779d477ffe1ebbf6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "How does the model perform, compared to the model obtained in step 4? Create one plot with the training accuracy and another with the validation accuracy of the two scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "873c045fa2e6f22815a90194ed2785f3",
     "grade": true,
     "grade_id": "cell-e3e3990ba39bea67",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "f.suptitle('Best vs VGG model performance')\n",
    "plot_history(ax1, history_best, 'Best model accuracy', {'Training': 'acc', 'Validation': 'val_acc'})\n",
    "plot_history(ax2, history_vgg, 'VGG model accuracy', {'Training': 'acc', 'Validation': 'val_acc'})y\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "49a22cb7fa7d4bc6335f5185d419101e",
     "grade": false,
     "grade_id": "cell-b84dd461d5ddcc8d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Compare these results. Which approach worked best, starting from scratch or doing transfer learning? Explain how you evaluated this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "58110ed91d1dc2020287d64755fafddd",
     "grade": true,
     "grade_id": "cell-f9e1a6a643946cd2",
     "locked": false,
     "points": 0.25,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f1d1fd0b9a00091e75a5bd0eaa19a8bf",
     "grade": false,
     "grade_id": "cell-c8afb448c67da5f8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "What are the main differences between the ImageNet dataset and the Dogs vs Cats dataset we used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "36cc539d06e12eba46249e29640ce6a1",
     "grade": true,
     "grade_id": "cell-2be321b63232ae01",
     "locked": false,
     "points": 0.25,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** Dogs vs Cats contains thousands of images of both dogs and cats, whereas ImageNet contains only a few hundred of them (see [ImageNet Explore tool](http://image-net.org/explore)). But it also contains millions of images of other categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1c0b0eae153b6076ca628a773203df42",
     "grade": false,
     "grade_id": "cell-71a8b8de004f6e57",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Even though there are considerable differences between these datasets, why is it that transfer learning is still a good idea?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7a990cd4099df100c9dc733bee0db608",
     "grade": true,
     "grade_id": "cell-655d00face15a862",
     "locked": false,
     "points": 0.25,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2d9425a067d87ef11d206088e82bb3c7",
     "grade": false,
     "grade_id": "cell-19785940b9624d2c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In which scenario would transfer learning be unsuitable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8ab35c98ddf1c98635eb188a197fd885",
     "grade": true,
     "grade_id": "cell-e79df7472ff5506a",
     "locked": false,
     "points": 0.25,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bbea73c6a2825f9b3e730907ba3ae71f",
     "grade": false,
     "grade_id": "cell-111f2b1d28919293",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Save the model to a HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_based_model.save('trans_learning_top_only.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8b8007704893660e8abc0c87b9028923",
     "grade": false,
     "grade_id": "cell-544a73726bebe121",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 5.2 Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6b5a44cfe68ff124f447339454f4f3ee",
     "grade": false,
     "grade_id": "cell-1ee9ebc87fd3358e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now that we have a better starting point for the top layers, we can train the entire network. Unfreeze the bottom layers.\n",
    "\n",
    "Tip:\n",
    "- Always recompile your model after changing anything in it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "412d6cf989068c151bd4b3f4085e7194",
     "grade": true,
     "grade_id": "cell-3918c2cdd9817f7e",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "model = load_model('trans_learning_top_only.h5')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# ALWAYS COMPILE\n",
    "model.compile(loss='binary_crossentropy',optimizer = Adam(lr=0.05, decay=0.01),metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ff2a177a54d2f9830995848f8de425b8",
     "grade": false,
     "grade_id": "cell-80fa8c89f1b262f1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Create the callbacks (if any) you would like to use for this training here, compile the model, and train it.\n",
    "\n",
    "Tip:\n",
    "- Even though we do have a decent starting point for the optimization, it's still possible that a bad hyper-parameter choice wrecks the preinitialization. Make sure to use a small learning rate for this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6814e17803f83868b0fd75d82f421ec3",
     "grade": true,
     "grade_id": "cell-594c6039216461e5",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "# train_generator = get_data_generator(train_data_path_small)\n",
    "# val_generator = get_data_generator(val_data_path_small)\n",
    "\n",
    "callbacks_final = [\n",
    "    TensorBoard(log_dir='./logs/final_vgg_final'),\n",
    "    EarlyStopping(monitor='val_loss', \n",
    "                  min_delta=0.2,\n",
    "                  patience=5,\n",
    "                  verbose=0, \n",
    "                  mode='auto',\n",
    "                  baseline=0.8,\n",
    "                  restore_best_weights=False),\n",
    "]\n",
    "\n",
    "history_vgg_final = model.fit_generator(train_generator, epochs=40, verbose=1, \n",
    "                                            callbacks=callbacks_final, \n",
    "                                            validation_data=val_generator,\n",
    "                                            validation_steps= 1500// batch_size,\n",
    "                                            steps_per_epoch = 3500// batch_size,\n",
    "                                            workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "653d29a729772d9cb73bfbe24fc76065",
     "grade": false,
     "grade_id": "cell-5dc3e388a41da3ed",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "How does the model perform, compared to the model trained with freezed layers? Create one plot with the training accuracy and another with the validation accuracy of the two scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b7b2e69e2ffc7f5bff07ba62225b4cee",
     "grade": true,
     "grade_id": "cell-7edb12ee397ec817",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "f.suptitle('VGG frozen vs VGG unfrozen model performance')\n",
    "plot_history(ax1, history_vgg, 'VGG frozen model accuracy', {'Training': 'acc', 'Validation': 'val_acc'})\n",
    "plot_history(ax2, history_vgg_final, 'VGG unfrozen model accuracy', {'Training': 'acc', 'Validation': 'val_acc'})y\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c14cf7017869bbc745425dc4c9d4a7a9",
     "grade": false,
     "grade_id": "cell-5dae528a81d5ff24",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Did the model's performance improve? Why (why not)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "69dfca588131944b0e9825a1532de432",
     "grade": true,
     "grade_id": "cell-0f4a5edca490320e",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b4d50b78d6ec765ce5b0f627873fa5e3",
     "grade": false,
     "grade_id": "cell-4ed3967e4f6c5f7f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Save the model to a HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('trans_learning_full.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "512bd4321118a59c1774035ffde4470d",
     "grade": false,
     "grade_id": "cell-56908ee1e60aa411",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 5.3 Improving the top model (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a63ad0cdc8ae853a3b9b6ebd16904186",
     "grade": false,
     "grade_id": "cell-3c8d8e5ab949ee35",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Improve the architecture for the layers you add on top of VGG16. Try different ideas, and consider comparing them using tensorboard. When you're happy with one architecture, copy it in the cell below and train it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8e78037ef98c08769cd8104d7541cb51",
     "grade": true,
     "grade_id": "cell-22d09c8401d84b61",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d040142833a356a7174729a7a8aadb1c",
     "grade": false,
     "grade_id": "cell-48933baad6c5afeb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "How does the model perform, compared to the model trained in step 5.2? Create one plot with the training accuracy and another with the validation accuracy of the two scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0bac4e10ca36850170af565096710d1c",
     "grade": true,
     "grade_id": "cell-7cb62a04916a848e",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "729c848775b6b7c20775151cffe38bfa",
     "grade": false,
     "grade_id": "cell-8bbfa3e11e2dfff9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Save the model to a HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('best_trans_learning.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4b192e3a46581dd6f57326ddb21ee49c",
     "grade": false,
     "grade_id": "cell-ad0efbac33de5a65",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 6. Final training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6e460754d2c0f05f0e79ae982a3fe3d3",
     "grade": false,
     "grade_id": "cell-cf811afdac96843b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now we'll train the model that achieved the best performance so far using the entire dataset.\n",
    "\n",
    "**Note**: start the optimization with the weights you obtained training in the smaller subset, i.e. *not* from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "10fada090ba96eae198313ce7e9f1e22",
     "grade": false,
     "grade_id": "cell-3ae2a65188e4ac74",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "First, create two new data generators, one for training samples and one for validation samples. This time, they'll load data from the folders for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "62bfd99d9d34913ada18493c74745706",
     "grade": true,
     "grade_id": "cell-64eaa83780f5eac9",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "model = load_model('trans_learning_full.h5')\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e7ae11154dee1b18040a35a6990ed284",
     "grade": false,
     "grade_id": "cell-f3f79586de42561b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Create the callbacks you would like to use and train your model. This optimization might take a long time, so TensorBoard is advised ;)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bad26172f9b786e6209e418f1ace058e",
     "grade": true,
     "grade_id": "cell-c7dd71a632b5f152",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d0ab46f558fb4b49f877ca0bae45376b",
     "grade": false,
     "grade_id": "cell-b1861d3a543c6386",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "How does the model perform now when trained on the entire dataset, compared to when only trained on the smaller subset of data? Create one plot with the training accuracy and another with the validation accuracy of the two scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "52bacfa672fbc7eca004c87d041e3411",
     "grade": true,
     "grade_id": "cell-ceaac6be60ce36a9",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fa3d1d443f52a1489ac198ca29ddd0c9",
     "grade": false,
     "grade_id": "cell-b38092b08c150e7d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "What can you conclude from these plots?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3a4a7b569af9834b505cc8d5daffb2d1",
     "grade": true,
     "grade_id": "cell-694a3fbb7f081da8",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "da9293dc623b91059c547544b509ad7b",
     "grade": false,
     "grade_id": "cell-5e1ddfbfceb4d194",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 7. Evaluation on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cd96692057f0be0c7cb1e9c2769f0991",
     "grade": false,
     "grade_id": "cell-a97630bf5d85363f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now we'll evaluate your final model, obtained in step 6, on the test set. As mentioned before, the samples in the test set are not labeled, so we can't compute any performance metrics ourselves. Instead, we'll create a .csv file containing the predictions for each sample, and submit it to Kaggle for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "891007ea6b998a0bfd810187d1e87208",
     "grade": false,
     "grade_id": "cell-96a8fded54ed7011",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Compute the predictions for all samples in the test set according to your best model, and save it in a .csv file with the format expected by the competition.\n",
    "\n",
    "Tip:\n",
    "- There is a sample_submission file available for download in the same place where you downloaded the data from. Take a look at it to better understand what is the expected format here.\n",
    "\n",
    "Hints:\n",
    "- The Python module `os` has a `listdir` function, which returns the filenames of all files in a given path.\n",
    "- If you don't know how to create and write to files with Python, Google can help.\n",
    "- Keras has a submodule called `preprocessing.image`, with some handy functions (for instance `load_img` and `img_to_array`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e235a9ab5690a066143575414247f751",
     "grade": true,
     "grade_id": "cell-cc77ac7849f856e1",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1e57b252395ed2657e8f39a69dbf4248",
     "grade": false,
     "grade_id": "cell-faf8664f26ff7f4e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now that you created your submission file, submit it to Kaggle for evaluation. The [old competition](https://www.kaggle.com/c/dogs-vs-cats) does not allow submissions any more, so submit your file to the [new one](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition). Kaggle evaluates your submission according to your log-loss score. Which score did you obtain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e4a90a8a13658eeb9af3ad05c63220de",
     "grade": true,
     "grade_id": "cell-e951dcec64dec85d",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e8a7f3a8236f43994efe29067d7237c2",
     "grade": false,
     "grade_id": "cell-dc362abcfef32eae",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "What was the username you used for this submission?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8cc61665c676edcd9192df3c15714aa3",
     "grade": true,
     "grade_id": "cell-d519532bb1f957c3",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
